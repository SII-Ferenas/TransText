# TransText: Alpha-as-RGB Representation for Transparent Text Animation

Fei Zhang <sup>1,2</sup>, Zijian Zhou <sup>3</sup>, Bohao Tang<sup>1,2</sup>, Sen He<sup>3</sup>, Hang Li<sup>3</sup>, Zhe Wang<sup>3</sup>, Soubhik Sanyal<sup>3</sup>, Pengfei Liu<sup>1,2</sup>, Viktar Atliha<sup>3</sup>, Tao Xiang<sup>3</sup>, Frost Xu<sup>3</sup>, Semih Gunel<sup>3</sup>


<sup>1</sup> Shanghai Jiao Tong University &nbsp;&nbsp;&nbsp; <sup>2</sup> Shanghai Innovation Institute &nbsp;&nbsp;&nbsp; <sup>3</sup> Meta AI


**The training and inference code will be released once it has been organized. Please stay tuned.**


## Project Overview

**TransText** is the first framework for reference-to-video (I2V) glyph generation. Our framework jointly models appearance and transparency by embedding the alpha channel into an RGB-compatible latent space, utilizing a specialized $\alpha$-reconstruction loss and structural trimap conditioning to ensure high-fidelity, cross-modal consistency in transparent text animations.

## Citation

If you find TransText useful for your research, please cite our paper:

<!-- ```bibtex
@article{zhang2025scaling,
    title={Scaling Zero-Shot Reference-to-Video Generation},
    author={Zhou, Zijian and Liu, Shikun and Liu, Haozhe and Qiu, Haonan and An, Zhaochong and Ren, Weiming and Liu, Zhiheng and Huang, Xiaoke and Ng, Kam Woh and Xie, Tian and Han, Xiao and Cong, Yuren and Li, Hang and Zhu, Chuyan and Patel, Aditya and Xiang, Tao and He, Sen},
    journal={arXiv preprint arXiv:2512.06905},
    year={2025}
}
``` -->
